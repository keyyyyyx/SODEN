{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f61ee42-9bf1-475e-9c6d-6639d5d915cd",
   "metadata": {},
   "source": [
    "## Test torch functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0db9e84-8a6f-4fce-bf33-33d88fa21a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mysoden\n"
     ]
    }
   ],
   "source": [
    "# check current working env\n",
    "import os\n",
    "print(os.environ['CONDA_DEFAULT_ENV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76ee8fc2-fb84-45ae-a406-1a44fdc45d4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26ffc7c0-d141-47de-931b-9294d9c1b4b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6d07e94-02d0-4ec7-8d3b-e584ac1adb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view: Returns a new tensor with the same data as the self tensor but of a different shape.\n",
    "Lambda_t = y.index_select(-1, torch.tensor([0])).view(-1, 1) ## retrieve Lambda_t from y, returns as a 2-D tensor of 1 element\n",
    "Lambda_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60dd881d-ad3b-40c6-81a4-6591bcb6af45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = y.index_select(-1, torch.tensor([1])).view(-1, 1)  ## retrieve the final time step T from y, returns as a 2-D tensor of 1 element\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "087a3b64-03e0-4ca1-8390-dcb1d2d0fa4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5, 6])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = y.index_select(-1, torch.tensor(range(2, y.size(-1))))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbbf0038-ace7-458b-831d-1521d127826c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c9/0gy2v_0d78n1jtsyrj6hc4qm0000gn/T/ipykernel_39378/3381573197.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(x, dtype=torch.long)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5, 6])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(x, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d3a42c7-b513-4f0b-a258-af0a56839cf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5, 6])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9fcec90-1d04-48f2-81e2-377366a10498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "feature_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b15fedda-cb10-4822-8a04-57f961509d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4078, -0.7414, -1.5151, -0.7076],\n",
       "        [-0.2540,  0.5423, -0.4350,  1.1568],\n",
       "        [-0.7054, -0.3997,  0.3515, -0.0304],\n",
       "        [ 2.1536,  0.7084, -0.3678, -1.0363]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = nn.Embedding(1602, feature_size)\n",
    "embed(x.to(torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38dfae83-22fb-4f47-bddd-c48558ce7310",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor(5)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6725fa31-eb60-4231-bf8e-3df74ff031db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 10,  3,  4,  5,  6]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate Lambda_t, t*T, and x into a 1-D tensor\n",
    "inp = torch.cat(\n",
    "            [Lambda_t,\n",
    "             t.repeat(T.size()) * T,  # s = t * T\n",
    "             x.view(-1, feature_size)], dim=1)\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44df47fa-dd26-4ff3-aeee-e92ee9a8b1a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "906dcc31-e957-4f3f-8a0d-cab752cef996",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a7bfaec6-cbff-4b23-8835-701b7013c101",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.repeat(T.size()) # Repeats the tensor t along the specified dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a2ee94a-e779-49ac-a622-65204fad5ad5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.repeat(T.size()) * T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e7d5ec26-798d-45aa-b34a-cf347954adc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "589b9e3e-c622-44d2-98f5-d96af67e9577",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5, 6])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "89fa6eb9-7c1d-447e-91fb-f9fbd23e6850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## make a complete nn model with specified layers and sizes\n",
    "def make_net(input_size, hidden_size, num_layers, output_size, dropout=0,\n",
    "             batch_norm=False, act=\"relu\", softplus=True):\n",
    "    if act == \"selu\":\n",
    "        ActFn = nn.SELU\n",
    "    else:\n",
    "        ActFn = nn.ReLU\n",
    "    modules = [nn.Linear(input_size, hidden_size), ActFn()]   ## Applies a linear transformation to the incoming data\n",
    "    if batch_norm:\n",
    "        modules.append(nn.BatchNorm1d(hidden_size))\n",
    "    if dropout > 0:\n",
    "        modules.append(nn.Dropout(p=dropout))\n",
    "    if num_layers > 1:\n",
    "        for _ in range(num_layers - 1):\n",
    "            modules.append(nn.Linear(hidden_size, hidden_size))\n",
    "            modules.append(ActFn())\n",
    "            if batch_norm:\n",
    "                modules.append(nn.BatchNorm1d(hidden_size))\n",
    "            if dropout > 0:\n",
    "                modules.append(nn.Dropout(p=dropout))\n",
    "    modules.append(nn.Linear(hidden_size, output_size))\n",
    "    if softplus:  # ODE models\n",
    "        modules.append(nn.Softplus())\n",
    "    return nn.Sequential(*modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cf795c90-1e93-4e53-8bb7-6496fcd86204",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = make_net(6, 3, num_layers = 2, output_size = 1, dropout=0,\n",
    "             batch_norm=False, act=\"relu\", softplus=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "af77239f-43d1-4434-9217-206e5dad07f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# solve dtype error\n",
    "inp.dtype\n",
    "inp = inp.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ce4e2130-40cd-419c-9f6c-88c2162975d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4979]], grad_fn=<SoftplusBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e872a6cf-d467-4eb3-9376-d6b02c944372",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9958]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(inp) * T\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "caaefc67-76aa-4a91-b266-6e113d35f5e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [6]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77f36ec-0c08-47ba-bc3a-ecbfe3f28aca",
   "metadata": {},
   "source": [
    "## Test foward function in NonCoxFuncModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "507c98f3-9ddf-4a46-9d5f-6f86c8415340",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a sample input\n",
    "inputs = {\n",
    "  \"t\": torch.tensor(5),\n",
    "  \"init_cond\": torch.tensor(1),\n",
    "  \"features\": torch.tensor([[3, 4, 5, 6]])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5cbd4bba-fa66-409c-bcf9-c79431a0742a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:  tensor(5)\n",
      "init_cond:  tensor(1)\n",
      "features:  tensor([[3, 4, 5, 6]])\n",
      "new t:  tensor([0., 1.])\n"
     ]
    }
   ],
   "source": [
    "# retrieve information from input\n",
    "t = inputs[\"t\"]\n",
    "print(\"t: \", t)\n",
    "init_cond = inputs[\"init_cond\"]\n",
    "print(\"init_cond: \", init_cond)\n",
    "features = inputs[\"features\"]\n",
    "print(\"features: \", features)\n",
    "init_cond = torch.cat([init_cond.view(-1, 1), t.view(-1, 1), features], dim=1)  ## rearrange; equiv to c(init_cond, t, features)\n",
    "t = torch.tensor([0., 1.])\n",
    "print(\"new t: \", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "434fdb69-e40e-4a2e-901d-c8cd1dd3a513",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_cond.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2ecde82b-0c07-4506-97a8-94138fa86472",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bf694bde-c468-488f-b89e-238ba642cced",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 5, 3, 4, 5, 6]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6500e835-6946-4153-baf4-c3606ebb7600",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BaseSurvODEFunc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseSurvODEFunc, self).__init__()\n",
    "        self.nfe = 0\n",
    "        self.batch_time_mode = False\n",
    "\n",
    "    def set_batch_time_mode(self, mode=True):\n",
    "        self.batch_time_mode = mode\n",
    "        # `odeint` requires the output of `odefunc` to have the same size as\n",
    "        # `init_cond` despite the how many steps we are going to evaluate. Set\n",
    "        # `self.batch_time_mode` to `False` before calling `odeint`. However,\n",
    "        # when we want to call the forward function of `odefunc` directly and\n",
    "        # when we would like to evaluate multiple time steps at the same time,\n",
    "        # set `self.batch_time_mode` to `True` and the output will have size\n",
    "        # (len(t), size(y)).\n",
    "\n",
    "    ## What is nfe??\n",
    "    def reset_nfe(self):\n",
    "        self.nfe = 0\n",
    "\n",
    "    def forward(self, t, y):\n",
    "        raise NotImplementedError(\"Not implemented.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "858debe2-8527-440f-8a0a-4c073393609a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContextRecMLPODEFunc(BaseSurvODEFunc):\n",
    "    def __init__(self, feature_size, hidden_size, num_layers, batch_norm=False,\n",
    "                 use_embed=True):\n",
    "        super(ContextRecMLPODEFunc, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_norm = batch_norm\n",
    "        self.use_embed = use_embed\n",
    "        if use_embed:\n",
    "            self.embed = nn.Embedding(1602, self.feature_size)  ## A simple lookup table that maps index value to a weighted matrix of certain dimension\n",
    "        else:\n",
    "            self.embed = None\n",
    "        self.net = make_net(input_size=feature_size+2, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, output_size=1,\n",
    "                            batch_norm=batch_norm)\n",
    "    \n",
    "    ## ---where does the y come from?--- passed within odeint as init_cond?\n",
    "    ## forward propagetion; one step forward\n",
    "    ## outputs a number from nn\n",
    "    def forward(self, t, y):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "          t: When self.batch_time_mode is False, t is a scalar indicating the\n",
    "            time step to be evaluated. When self.batch_time_mode is True, t is\n",
    "            a 1-D tensor with a single element [1.0].\n",
    "          y: When self.batch_time_mode is False, y is a 1-D tensor with length\n",
    "            2 + k, where the first dim indicates Lambda_t, the second dim\n",
    "            indicates the final time step T to be evaluated, and the remaining\n",
    "            k dims indicates the features. When self.batch_time_mode is True, y\n",
    "            is a 2-D tensor with batch_size * (2 + k).\n",
    "        \"\"\"\n",
    "        self.nfe += 1\n",
    "        device = next(self.parameters()).device\n",
    "        Lambda_t = y.index_select(-1, torch.tensor([0]).to(device)).view(-1, 1) ## retrieve Lambda_t from y, returns as a 2-D tensor of 1 element\n",
    "        T = y.index_select(-1, torch.tensor([1]).to(device)).view(-1, 1)  ## retrieve the final time step T from y, returns as a 2-D tensor of 1 element\n",
    "        x = y.index_select(-1, torch.tensor(range(2, y.size(-1))).to(device))  ## retrieve features from y, returns as a 1-D tensor\n",
    "        if self.use_embed:\n",
    "            x = torch.mean(\n",
    "                self.embed(torch.tensor(x, dtype=torch.long).to(device)),\n",
    "                dim=1)\n",
    "        # Rescaling trick  ## time rescaling\n",
    "        # $\\int_0^T f(s; x) ds = \\int_0^1 T f(tT; x) dt$, where $t = s / T$\n",
    "        inp = torch.cat(\n",
    "            [Lambda_t,\n",
    "             t.repeat(T.size()) * T,  # s = t * T; time step to be evaluated * final time step\n",
    "             x.view(-1, self.feature_size)], dim=1)\n",
    "        output = self.net(inp) * T  # f(tT; x) * T\n",
    "        zeros = torch.zeros_like(\n",
    "            y.index_select(-1, torch.tensor(range(1, y.size(-1))).to(device))\n",
    "        )  ## Returns a tensor filled with the scalar value 0, with the same size as input\n",
    "        output = torch.cat([output, zeros], dim=1)\n",
    "        if self.batch_time_mode:\n",
    "            return output\n",
    "        else:\n",
    "            return output.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2f82b4fe-92aa-451f-8ec1-9f8f3429158e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define sample config\n",
    "config = {\n",
    "    \"hidden_size\": 5,\n",
    "    \"num_layers\": 2,\n",
    "    \"batch_norm\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0337cafa-b66c-4c96-9602-ae9010e06fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define odefunc\n",
    "odefunc = ContextRecMLPODEFunc(\n",
    "                feature_size = 4, hidden_size = config[\"hidden_size\"], num_layers = config[\"num_layers\"],\n",
    "                batch_norm=config[\"batch_norm\"], use_embed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "added323-a943-4ad4-b088-d79250e99e98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initilize output\n",
    "outputs = {}\n",
    "# import ode solver\n",
    "from torchdiffeq import odeint_adjoint as odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "82e894bf-7219-4133-93de-1384fdf85428",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lambda': tensor([[4.2693, 5.0000, 3.0000, 4.0000, 5.0000, 6.0000]],\n",
      "       grad_fn=<ViewBackward0>), 'lambda': tensor([3.2847, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "       grad_fn=<SqueezeBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "# change init_cond to floating point Tensor to fix datatype error\n",
    "init_cond = init_cond.to(torch.float)\n",
    "# solve ode for Lambda\n",
    "outputs[\"Lambda\"] = odeint(odefunc, init_cond, t, rtol=1e-4, atol=1e-8)[1:].squeeze()  # size: [length of t] x [batch size] x [dim of y0]  ## Solve ODE for cumulative hazard function\n",
    "outputs[\"Lambda\"] = outputs[\"Lambda\"].view(1, outputs[\"Lambda\"].size(-1)) ## add to fix dimension error\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c552781f-98d8-47f1-b25f-db0549bf5b21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lambda': tensor([4.2693], grad_fn=<SelectBackward0>), 'lambda': tensor([0.6569], grad_fn=<DivBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "# add outputs\n",
    "odefunc.set_batch_time_mode(True)\n",
    "outputs[\"lambda\"] = odefunc(t[1:], outputs[\"Lambda\"]).squeeze()\n",
    "outputs[\"lambda\"] = outputs[\"lambda\"].view(1, outputs[\"lambda\"].size(-1)) ## add to fix dimension error\n",
    "outputs[\"Lambda\"] = outputs[\"Lambda\"][:, 0]\n",
    "outputs[\"lambda\"] = outputs[\"lambda\"][:, 0] / inputs[\"t\"]\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0d7a25-0f77-4f1f-a266-ea46f8936b93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "775f967b-2368-44a6-8377-fe0a8e5893b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# debug\n",
    "t[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "99e7b33e-5fea-46c5-8b85-3b9a40774a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[\"Lambda\"].dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2e83e3c1-b78d-40e0-9cba-2b999a700070",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLambda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "outputs[\"Lambda\"][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e95cb837-addd-42c4-acfa-3d596878ee11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: tensor([[4.2693, 5.0000, 3.0000, 4.0000, 5.0000, 6.0000]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "t_1: tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "# debug dimsion error inside ContextRecMLPODEFunc\n",
    "# convert y to 2d solves the problem\n",
    "y = outputs[\"Lambda\"]\n",
    "y = y.view(1, 6)\n",
    "print(\"y:\", y)\n",
    "t_1 = t[1:]\n",
    "print(\"t_1:\", t_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8f2fe63f-3fb6-4f1f-9f64-b57d2cf1e509",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda_t: tensor([[4.2693]], grad_fn=<ViewBackward0>)\n",
      "T:  tensor([[5.]], grad_fn=<ViewBackward0>)\n",
      "x: tensor([[3., 4., 5., 6.]], grad_fn=<IndexSelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "Lambda_t = y.index_select(-1, torch.tensor([0])).view(-1, 1) ## retrieve Lambda_t from y, returns as a 2-D tensor of 1 element\n",
    "T = y.index_select(-1, torch.tensor([1])).view(-1, 1)  ## retrieve the final time step T from y, returns as a 2-D tensor of 1 element\n",
    "x = y.index_select(-1, torch.tensor(range(2, y.size(-1))))\n",
    "print(\"Lambda_t:\", Lambda_t)\n",
    "print(\"T: \", T)\n",
    "print(\"x:\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "63b726ad-ca95-4872-bad2-a15276870233",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp: tensor([[4.2693, 5.0000, 3.0000, 4.0000, 5.0000, 6.0000]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "output: tensor([[2.7066]], grad_fn=<MulBackward0>)\n",
      "zeros: tensor([[0., 0., 0., 0., 0.]])\n",
      "output: tensor([[2.7066, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "feature_size = 4\n",
    "inp = torch.cat([Lambda_t, t_1.repeat(T.size()) * T,  # s = t * T; time step to be evaluated * final time step\n",
    "             x.view(-1, feature_size)], dim=1)\n",
    "print(\"inp:\", inp)\n",
    "output = net(inp) * T  # f(tT; x) * T\n",
    "print(\"output:\", output)\n",
    "zeros = torch.zeros_like(y.index_select(-1, torch.tensor(range(1, y.size(-1)))))  ## Returns a tensor filled with the scalar value 0, with the same size as input\n",
    "print(\"zeros:\", zeros)\n",
    "output = torch.cat([output, zeros], dim=1)\n",
    "print(\"output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8fa293e5-687f-4448-9efd-7703443b21de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(t_1.repeat(T.size()) * T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "81ae0866-a6a9-4701-8197-f3a12acc6d44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0db4e834-6c71-4b93-9524-1a71539fe1eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e59321d5-60ad-46b1-a22c-8af88ac440fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be29862-5d21-4494-a67c-739b19f24f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
