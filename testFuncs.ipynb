{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f61ee42-9bf1-475e-9c6d-6639d5d915cd",
   "metadata": {},
   "source": [
    "## Test torch functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0db9e84-8a6f-4fce-bf33-33d88fa21a3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mysoden\n"
     ]
    }
   ],
   "source": [
    "# check current working env\n",
    "import os\n",
    "print(os.environ['CONDA_DEFAULT_ENV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76ee8fc2-fb84-45ae-a406-1a44fdc45d4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26ffc7c0-d141-47de-931b-9294d9c1b4b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6d07e94-02d0-4ec7-8d3b-e584ac1adb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view: Returns a new tensor with the same data as the self tensor but of a different shape.\n",
    "Lambda_t = y.index_select(-1, torch.tensor([0])).view(-1, 1) ## retrieve Lambda_t from y, returns as a 2-D tensor of 1 element\n",
    "Lambda_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60dd881d-ad3b-40c6-81a4-6591bcb6af45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = y.index_select(-1, torch.tensor([1])).view(-1, 1)  ## retrieve the final time step T from y, returns as a 2-D tensor of 1 element\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "087a3b64-03e0-4ca1-8390-dcb1d2d0fa4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5, 6])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = y.index_select(-1, torch.tensor(range(2, y.size(-1))))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbbf0038-ace7-458b-831d-1521d127826c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c9/0gy2v_0d78n1jtsyrj6hc4qm0000gn/T/ipykernel_39378/3381573197.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(x, dtype=torch.long)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5, 6])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(x, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d3a42c7-b513-4f0b-a258-af0a56839cf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5, 6])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9fcec90-1d04-48f2-81e2-377366a10498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "feature_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b15fedda-cb10-4822-8a04-57f961509d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4078, -0.7414, -1.5151, -0.7076],\n",
       "        [-0.2540,  0.5423, -0.4350,  1.1568],\n",
       "        [-0.7054, -0.3997,  0.3515, -0.0304],\n",
       "        [ 2.1536,  0.7084, -0.3678, -1.0363]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = nn.Embedding(1602, feature_size)\n",
    "embed(x.to(torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38dfae83-22fb-4f47-bddd-c48558ce7310",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor(5)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6725fa31-eb60-4231-bf8e-3df74ff031db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 10,  3,  4,  5,  6]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate Lambda_t, t*T, and x into a 1-D tensor\n",
    "inp = torch.cat(\n",
    "            [Lambda_t,\n",
    "             t.repeat(T.size()) * T,  # s = t * T\n",
    "             x.view(-1, feature_size)], dim=1)\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44df47fa-dd26-4ff3-aeee-e92ee9a8b1a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "906dcc31-e957-4f3f-8a0d-cab752cef996",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a7bfaec6-cbff-4b23-8835-701b7013c101",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.repeat(T.size()) # Repeats the tensor t along the specified dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a2ee94a-e779-49ac-a622-65204fad5ad5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.repeat(T.size()) * T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e7d5ec26-798d-45aa-b34a-cf347954adc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "589b9e3e-c622-44d2-98f5-d96af67e9577",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5, 6])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "89fa6eb9-7c1d-447e-91fb-f9fbd23e6850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## make a complete nn model with specified layers and sizes\n",
    "def make_net(input_size, hidden_size, num_layers, output_size, dropout=0,\n",
    "             batch_norm=False, act=\"relu\", softplus=True):\n",
    "    if act == \"selu\":\n",
    "        ActFn = nn.SELU\n",
    "    else:\n",
    "        ActFn = nn.ReLU\n",
    "    modules = [nn.Linear(input_size, hidden_size), ActFn()]   ## Applies a linear transformation to the incoming data\n",
    "    if batch_norm:\n",
    "        modules.append(nn.BatchNorm1d(hidden_size))\n",
    "    if dropout > 0:\n",
    "        modules.append(nn.Dropout(p=dropout))\n",
    "    if num_layers > 1:\n",
    "        for _ in range(num_layers - 1):\n",
    "            modules.append(nn.Linear(hidden_size, hidden_size))\n",
    "            modules.append(ActFn())\n",
    "            if batch_norm:\n",
    "                modules.append(nn.BatchNorm1d(hidden_size))\n",
    "            if dropout > 0:\n",
    "                modules.append(nn.Dropout(p=dropout))\n",
    "    modules.append(nn.Linear(hidden_size, output_size))\n",
    "    if softplus:  # ODE models\n",
    "        modules.append(nn.Softplus())\n",
    "    return nn.Sequential(*modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cf795c90-1e93-4e53-8bb7-6496fcd86204",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = make_net(6, 3, num_layers = 2, output_size = 1, dropout=0,\n",
    "             batch_norm=False, act=\"relu\", softplus=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "af77239f-43d1-4434-9217-206e5dad07f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# solve dtype error\n",
    "inp.dtype\n",
    "inp = inp.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ce4e2130-40cd-419c-9f6c-88c2162975d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4979]], grad_fn=<SoftplusBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e872a6cf-d467-4eb3-9376-d6b02c944372",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9958]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(inp) * T\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "caaefc67-76aa-4a91-b266-6e113d35f5e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [6]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77f36ec-0c08-47ba-bc3a-ecbfe3f28aca",
   "metadata": {},
   "source": [
    "## Test foward function in NonCoxFuncModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "507c98f3-9ddf-4a46-9d5f-6f86c8415340",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a sample input\n",
    "inputs = {\n",
    "  \"t\": torch.tensor(5),\n",
    "  \"init_cond\": torch.tensor(1),\n",
    "  \"features\": torch.tensor([[3, 4, 5, 6]])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5cbd4bba-fa66-409c-bcf9-c79431a0742a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:  tensor(5)\n",
      "init_cond:  tensor(1)\n",
      "features:  tensor([[3, 4, 5, 6]])\n",
      "new t:  tensor([0., 1.])\n"
     ]
    }
   ],
   "source": [
    "# retrieve information from input\n",
    "t = inputs[\"t\"]\n",
    "print(\"t: \", t)\n",
    "init_cond = inputs[\"init_cond\"]\n",
    "print(\"init_cond: \", init_cond)\n",
    "features = inputs[\"features\"]\n",
    "print(\"features: \", features)\n",
    "init_cond = torch.cat([init_cond.view(-1, 1), t.view(-1, 1), features], dim=1)  ## rearrange; equiv to c(init_cond, t, features)\n",
    "t = torch.tensor([0., 1.])\n",
    "print(\"new t: \", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "434fdb69-e40e-4a2e-901d-c8cd1dd3a513",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_cond.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2ecde82b-0c07-4506-97a8-94138fa86472",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bf694bde-c468-488f-b89e-238ba642cced",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 5, 3, 4, 5, 6]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6500e835-6946-4153-baf4-c3606ebb7600",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BaseSurvODEFunc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseSurvODEFunc, self).__init__()\n",
    "        self.nfe = 0\n",
    "        self.batch_time_mode = False\n",
    "\n",
    "    def set_batch_time_mode(self, mode=True):\n",
    "        self.batch_time_mode = mode\n",
    "        # `odeint` requires the output of `odefunc` to have the same size as\n",
    "        # `init_cond` despite the how many steps we are going to evaluate. Set\n",
    "        # `self.batch_time_mode` to `False` before calling `odeint`. However,\n",
    "        # when we want to call the forward function of `odefunc` directly and\n",
    "        # when we would like to evaluate multiple time steps at the same time,\n",
    "        # set `self.batch_time_mode` to `True` and the output will have size\n",
    "        # (len(t), size(y)).\n",
    "\n",
    "    ## What is nfe??\n",
    "    def reset_nfe(self):\n",
    "        self.nfe = 0\n",
    "\n",
    "    def forward(self, t, y):\n",
    "        raise NotImplementedError(\"Not implemented.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "858debe2-8527-440f-8a0a-4c073393609a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContextRecMLPODEFunc(BaseSurvODEFunc):\n",
    "    def __init__(self, feature_size, hidden_size, num_layers, batch_norm=False,\n",
    "                 use_embed=True):\n",
    "        super(ContextRecMLPODEFunc, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_norm = batch_norm\n",
    "        self.use_embed = use_embed\n",
    "        if use_embed:\n",
    "            self.embed = nn.Embedding(1602, self.feature_size)  ## A simple lookup table that maps index value to a weighted matrix of certain dimension\n",
    "        else:\n",
    "            self.embed = None\n",
    "        self.net = make_net(input_size=feature_size+2, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, output_size=1,\n",
    "                            batch_norm=batch_norm)\n",
    "    \n",
    "    ## ---where does the y come from?--- passed within odeint as init_cond?\n",
    "    ## forward propagetion; one step forward\n",
    "    ## outputs a number from nn\n",
    "    def forward(self, t, y):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "          t: When self.batch_time_mode is False, t is a scalar indicating the\n",
    "            time step to be evaluated. When self.batch_time_mode is True, t is\n",
    "            a 1-D tensor with a single element [1.0].\n",
    "          y: When self.batch_time_mode is False, y is a 1-D tensor with length\n",
    "            2 + k, where the first dim indicates Lambda_t, the second dim\n",
    "            indicates the final time step T to be evaluated, and the remaining\n",
    "            k dims indicates the features. When self.batch_time_mode is True, y\n",
    "            is a 2-D tensor with batch_size * (2 + k).\n",
    "        \"\"\"\n",
    "        self.nfe += 1\n",
    "        device = next(self.parameters()).device\n",
    "        Lambda_t = y.index_select(-1, torch.tensor([0]).to(device)).view(-1, 1) ## retrieve Lambda_t from y, returns as a 2-D tensor of 1 element\n",
    "        T = y.index_select(-1, torch.tensor([1]).to(device)).view(-1, 1)  ## retrieve the final time step T from y, returns as a 2-D tensor of 1 element\n",
    "        x = y.index_select(-1, torch.tensor(range(2, y.size(-1))).to(device))  ## retrieve features from y, returns as a 1-D tensor\n",
    "        if self.use_embed:\n",
    "            x = torch.mean(\n",
    "                self.embed(torch.tensor(x, dtype=torch.long).to(device)),\n",
    "                dim=1)\n",
    "        # Rescaling trick  ## time rescaling\n",
    "        # $\\int_0^T f(s; x) ds = \\int_0^1 T f(tT; x) dt$, where $t = s / T$\n",
    "        inp = torch.cat(\n",
    "            [Lambda_t,\n",
    "             t.repeat(T.size()) * T,  # s = t * T; time step to be evaluated * final time step\n",
    "             x.view(-1, self.feature_size)], dim=1)\n",
    "        output = self.net(inp) * T  # f(tT; x) * T\n",
    "        zeros = torch.zeros_like(\n",
    "            y.index_select(-1, torch.tensor(range(1, y.size(-1))).to(device))\n",
    "        )  ## Returns a tensor filled with the scalar value 0, with the same size as input\n",
    "        output = torch.cat([output, zeros], dim=1)\n",
    "        if self.batch_time_mode:\n",
    "            return output\n",
    "        else:\n",
    "            return output.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2f82b4fe-92aa-451f-8ec1-9f8f3429158e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define sample config\n",
    "config = {\n",
    "    \"hidden_size\": 5,\n",
    "    \"num_layers\": 2,\n",
    "    \"batch_norm\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0337cafa-b66c-4c96-9602-ae9010e06fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define odefunc\n",
    "odefunc = ContextRecMLPODEFunc(\n",
    "                feature_size = 4, hidden_size = config[\"hidden_size\"], num_layers = config[\"num_layers\"],\n",
    "                batch_norm=config[\"batch_norm\"], use_embed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "added323-a943-4ad4-b088-d79250e99e98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initilize output\n",
    "outputs = {}\n",
    "# import ode solver\n",
    "from torchdiffeq import odeint_adjoint as odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "82e894bf-7219-4133-93de-1384fdf85428",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lambda': tensor([[4.2693, 5.0000, 3.0000, 4.0000, 5.0000, 6.0000]],\n",
      "       grad_fn=<ViewBackward0>), 'lambda': tensor([3.2847, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "       grad_fn=<SqueezeBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "# change init_cond to floating point Tensor to fix datatype error\n",
    "init_cond = init_cond.to(torch.float)\n",
    "# solve ode for Lambda\n",
    "outputs[\"Lambda\"] = odeint(odefunc, init_cond, t, rtol=1e-4, atol=1e-8)[1:].squeeze()  # size: [length of t] x [batch size] x [dim of y0]  ## Solve ODE for cumulative hazard function\n",
    "outputs[\"Lambda\"] = outputs[\"Lambda\"].view(1, outputs[\"Lambda\"].size(-1)) ## add to fix dimension error\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c552781f-98d8-47f1-b25f-db0549bf5b21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lambda': tensor([4.2693], grad_fn=<SelectBackward0>), 'lambda': tensor([0.6569], grad_fn=<DivBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "# add outputs\n",
    "odefunc.set_batch_time_mode(True)\n",
    "outputs[\"lambda\"] = odefunc(t[1:], outputs[\"Lambda\"]).squeeze()\n",
    "outputs[\"lambda\"] = outputs[\"lambda\"].view(1, outputs[\"lambda\"].size(-1)) ## add to fix dimension error\n",
    "outputs[\"Lambda\"] = outputs[\"Lambda\"][:, 0]\n",
    "outputs[\"lambda\"] = outputs[\"lambda\"][:, 0] / inputs[\"t\"]\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0d7a25-0f77-4f1f-a266-ea46f8936b93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "775f967b-2368-44a6-8377-fe0a8e5893b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# debug\n",
    "t[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "99e7b33e-5fea-46c5-8b85-3b9a40774a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[\"Lambda\"].dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2e83e3c1-b78d-40e0-9cba-2b999a700070",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLambda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "outputs[\"Lambda\"][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e95cb837-addd-42c4-acfa-3d596878ee11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: tensor([[4.2693, 5.0000, 3.0000, 4.0000, 5.0000, 6.0000]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "t_1: tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "# debug dimsion error inside ContextRecMLPODEFunc\n",
    "# convert y to 2d solves the problem\n",
    "y = outputs[\"Lambda\"]\n",
    "y = y.view(1, 6)\n",
    "print(\"y:\", y)\n",
    "t_1 = t[1:]\n",
    "print(\"t_1:\", t_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8f2fe63f-3fb6-4f1f-9f64-b57d2cf1e509",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda_t: tensor([[4.2693]], grad_fn=<ViewBackward0>)\n",
      "T:  tensor([[5.]], grad_fn=<ViewBackward0>)\n",
      "x: tensor([[3., 4., 5., 6.]], grad_fn=<IndexSelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "Lambda_t = y.index_select(-1, torch.tensor([0])).view(-1, 1) ## retrieve Lambda_t from y, returns as a 2-D tensor of 1 element\n",
    "T = y.index_select(-1, torch.tensor([1])).view(-1, 1)  ## retrieve the final time step T from y, returns as a 2-D tensor of 1 element\n",
    "x = y.index_select(-1, torch.tensor(range(2, y.size(-1))))\n",
    "print(\"Lambda_t:\", Lambda_t)\n",
    "print(\"T: \", T)\n",
    "print(\"x:\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "63b726ad-ca95-4872-bad2-a15276870233",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp: tensor([[4.2693, 5.0000, 3.0000, 4.0000, 5.0000, 6.0000]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "output: tensor([[2.7066]], grad_fn=<MulBackward0>)\n",
      "zeros: tensor([[0., 0., 0., 0., 0.]])\n",
      "output: tensor([[2.7066, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "feature_size = 4\n",
    "inp = torch.cat([Lambda_t, t_1.repeat(T.size()) * T,  # s = t * T; time step to be evaluated * final time step\n",
    "             x.view(-1, feature_size)], dim=1)\n",
    "print(\"inp:\", inp)\n",
    "output = net(inp) * T  # f(tT; x) * T\n",
    "print(\"output:\", output)\n",
    "zeros = torch.zeros_like(y.index_select(-1, torch.tensor(range(1, y.size(-1)))))  ## Returns a tensor filled with the scalar value 0, with the same size as input\n",
    "print(\"zeros:\", zeros)\n",
    "output = torch.cat([output, zeros], dim=1)\n",
    "print(\"output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8fa293e5-687f-4448-9efd-7703443b21de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(t_1.repeat(T.size()) * T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "81ae0866-a6a9-4701-8197-f3a12acc6d44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0db4e834-6c71-4b93-9524-1a71539fe1eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e59321d5-60ad-46b1-a22c-8af88ac440fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea929e5-9531-478e-b6b0-4fb2d43625c6",
   "metadata": {},
   "source": [
    "## Test SODENModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b45e7325-b020-42f7-8dc4-de144982cfc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# store NonCoxFuncModel\n",
    "## The proposed SODEN model\n",
    "class NonCoxFuncModel(nn.Module):\n",
    "    \"\"\"NonCoxFuncModel.\"\"\"\n",
    "\n",
    "    def __init__(self, model_config, feature_size=None, use_embed=False):\n",
    "        \"\"\"Initializes a NonCoxFuncModel.\n",
    "\n",
    "        Arguments:\n",
    "          model_config: An OrderedDict of lists. The keys of the dict indicate\n",
    "            the names of different parts of the model. Each value of the dict\n",
    "            is a list indicating the configs of layers in the corresponding\n",
    "            part. Each element of the list is a list [layer_type, arguments],\n",
    "            where layer_type is a string and arguments is a dict.\n",
    "          feature_size: Feature size.\n",
    "          use_embed: Whether to use embedding layer after input.\n",
    "        \"\"\"\n",
    "        assert feature_size is not None\n",
    "        super(NonCoxFuncModel, self).__init__()\n",
    "        self.model_config = model_config\n",
    "        self.feature_size = feature_size\n",
    "        config = model_config[\"ode\"][\"surv_ode_0\"]\n",
    "        self.func_type = config[\"func_type\"]\n",
    "\n",
    "        if self.func_type == \"rec_mlp\":\n",
    "            self.odefunc = ContextRecMLPODEFunc(\n",
    "                feature_size, config[\"hidden_size\"], config[\"num_layers\"],\n",
    "                batch_norm=config[\"batch_norm\"], use_embed=use_embed)     ## initialize ContextRecMLPODEFunc; ode function\n",
    "        else:\n",
    "            raise NotImplementedError(\"Function type %s is not supported.\"\n",
    "                                      % self.func_type)\n",
    "\n",
    "        self.set_last_eval(False)\n",
    "\n",
    "    def set_last_eval(self, last_eval=True):\n",
    "        self.last_eval = last_eval\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        device = next(self.parameters()).device\n",
    "        t = inputs[\"t\"]\n",
    "        init_cond = inputs[\"init_cond\"]\n",
    "        features = inputs[\"features\"]\n",
    "        init_cond = torch.cat([init_cond.view(-1, 1), t.view(-1, 1), features],\n",
    "                              dim=1)  ## rearrange; equiv to c(init_cond, t, features)\n",
    "        t = torch.tensor([0., 1.]).to(device)\n",
    "\n",
    "        outputs = {}\n",
    "        self.odefunc.set_batch_time_mode(False)\n",
    "        outputs[\"Lambda\"] = odeint(\n",
    "            self.odefunc, init_cond, t, rtol=1e-4, atol=1e-8)[1:].squeeze()  # size: [length of t] x [batch size] x [dim of y0]  ## Solve ODE for cumulative hazard function\n",
    "        self.odefunc.set_batch_time_mode(True)\n",
    "        outputs[\"lambda\"] = self.odefunc(t[1:], outputs[\"Lambda\"]).squeeze()  ## Solve ODE for hazard function\n",
    "        outputs[\"Lambda\"] = outputs[\"Lambda\"][:, 0]\n",
    "        outputs[\"lambda\"] = outputs[\"lambda\"][:, 0] / inputs[\"t\"]\n",
    "\n",
    "        if not self.training:  ## ---where is self.training defined?---\n",
    "            if self.last_eval and \"eval_t\" in inputs:\n",
    "                self.odefunc.set_batch_time_mode(False)\n",
    "                ones = torch.ones_like(inputs[\"t\"])\n",
    "                # Eval for time-dependent C-index\n",
    "                outputs[\"t\"] = inputs[\"t\"]\n",
    "                outputs[\"eval_t\"] = inputs[\"eval_t\"]\n",
    "                t = inputs[\"eval_t\"][-1] * ones\n",
    "                init_cond = inputs[\"init_cond\"]\n",
    "                features = inputs[\"features\"]\n",
    "                init_cond = torch.cat(\n",
    "                    [init_cond.view(-1, 1), t.view(-1, 1), features],\n",
    "                    dim=1)\n",
    "                t_max = inputs[\"eval_t\"][-1]\n",
    "                t = inputs[\"eval_t\"] / t_max\n",
    "                t = torch.cat([torch.zeros([1]).to(device), t], dim=0)\n",
    "                outputs[\"cum_hazard_seqs\"] = odeint(\n",
    "                    self.odefunc, init_cond, t, rtol=1e-4, atol=1e-8)[1:, :, 0]  \n",
    "\n",
    "                # Eval for Brier Score\n",
    "                t = inputs[\"t_max\"] * ones\n",
    "                init_cond = inputs[\"init_cond\"]\n",
    "                features = inputs[\"features\"]\n",
    "                init_cond = torch.cat(\n",
    "                    [init_cond.view(-1, 1), t.view(-1, 1), features],\n",
    "                    dim=1)\n",
    "                t_min = inputs[\"t_min\"]\n",
    "                t_max = inputs[\"t_max\"]\n",
    "                t = torch.linspace(\n",
    "                    t_min, t_max, NUM_INT_STEPS, dtype=init_cond.dtype,\n",
    "                    device=device)\n",
    "                t = torch.cat([torch.zeros([1]).to(device), t], dim=0)\n",
    "                t = t / t_max\n",
    "                outputs[\"survival_seqs\"] = torch.exp(\n",
    "                    -odeint(self.odefunc, init_cond, t, rtol=1e-4,\n",
    "                            atol=1e-8)[1:, :, 0])\n",
    "\n",
    "                for eps in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "                    t = inputs[\"t_max_{}\".format(eps)] * ones\n",
    "                    init_cond = inputs[\"init_cond\"]\n",
    "                    features = inputs[\"features\"]\n",
    "                    init_cond = torch.cat(\n",
    "                        [init_cond.view(-1, 1), t.view(-1, 1), features],\n",
    "                        dim=1)\n",
    "                    t_min = inputs[\"t_min\"]\n",
    "                    t_max = inputs[\"t_max_{}\".format(eps)]\n",
    "                    t = torch.linspace(\n",
    "                        t_min, t_max, NUM_INT_STEPS, dtype=init_cond.dtype,\n",
    "                        device=device)\n",
    "                    t = torch.cat([torch.zeros([1]).to(device), t], dim=0)\n",
    "                    t = t / t_max\n",
    "                    outputs[\"survival_seqs_{}\".format(eps)] = torch.exp(\n",
    "                        -odeint(self.odefunc, init_cond, t, rtol=1e-4,\n",
    "                                atol=1e-8)[1:, :, 0])\n",
    "            \n",
    "            ## compute Lambda at q25, q50, and q75 \n",
    "            if \"t_q25\" in inputs:\n",
    "                outputs[\"t\"] = inputs[\"t\"]\n",
    "                self.odefunc.set_batch_time_mode(False)\n",
    "                for q in [\"q25\", \"q50\", \"q75\"]:\n",
    "                    t = inputs[\"t_%s\" % q]\n",
    "                    init_cond = inputs[\"init_cond\"]\n",
    "                    features = inputs[\"features\"]\n",
    "                    init_cond = torch.cat(\n",
    "                        [init_cond.view(-1, 1), t.view(-1, 1), features],\n",
    "                        dim=1)\n",
    "                    t = torch.tensor([0., 1.]).to(device)\n",
    "                    outputs[\"Lambda_%s\" % q] = odeint(\n",
    "                        self.odefunc, init_cond, t,\n",
    "                        rtol=1e-4, atol=1e-8)[1:].squeeze()\n",
    "                    outputs[\"Lambda_%s\" % q] = outputs[\"Lambda_%s\" % q][:, 0]\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5d9e88d2-9420-4c19-8559-8239c8bb7c1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_type': 'surv_ode', 'func_type': 'rec_mlp', 'hidden_size': 5, 'num_layers': 2, 'batch_norm': False}\n"
     ]
    }
   ],
   "source": [
    "# define sample model config\n",
    "model_config = {\n",
    "    \"ode\": {\n",
    "        \"surv_ode_0\": {\n",
    "            \"layer_type\": \"surv_ode\",\n",
    "            \"func_type\": \"rec_mlp\",\n",
    "            \"hidden_size\": 5,\n",
    "            \"num_layers\": 2,\n",
    "            \"batch_norm\": False\n",
    "        }\n",
    "    }\n",
    "}\n",
    "print(model_config[\"ode\"][\"surv_ode_0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e9199303-0a71-4a0b-9eb4-39d18d5f438b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RNNModel = nn.LSTM\n",
    "feature_size = {\n",
    "    \"seq_feat\": 5,\n",
    "    \"fix_feat\": 4\n",
    "}\n",
    "seq_feat_size = feature_size[\"seq_feat\"]\n",
    "rnn = RNNModel(input_size=seq_feat_size,\n",
    "                                hidden_size=3,\n",
    "                                num_layers=2,\n",
    "                                batch_first=True)\n",
    "feature_size = 3 + feature_size[\"fix_feat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7db4d3dc-81e0-46ee-8b2e-ab5f35f2bf04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = NonCoxFuncModel(model_config, 4, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "801fb7ce-0aaf-4ac9-812f-2b388fa11d17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "`y0` must be a floating point Tensor but is a torch.LongTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[134], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mysoden/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[129], line 49\u001b[0m, in \u001b[0;36mNonCoxFuncModel.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     47\u001b[0m outputs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39modefunc\u001b[38;5;241m.\u001b[39mset_batch_time_mode(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 49\u001b[0m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLambda\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43modefunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_cond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-8\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39msqueeze()  \u001b[38;5;66;03m# size: [length of t] x [batch size] x [dim of y0]  ## Solve ODE for cumulative hazard function\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39modefunc\u001b[38;5;241m.\u001b[39mset_batch_time_mode(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     52\u001b[0m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlambda\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39modefunc(t[\u001b[38;5;241m1\u001b[39m:], outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLambda\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39msqueeze()  \u001b[38;5;66;03m## Solve ODE for hazard function\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mysoden/lib/python3.10/site-packages/torchdiffeq/_impl/adjoint.py:192\u001b[0m, in \u001b[0;36modeint_adjoint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn, adjoint_rtol, adjoint_atol, adjoint_method, adjoint_options, adjoint_params)\u001b[0m\n\u001b[1;32m    188\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn adjoint parameter was passed without requiring gradient. For efficiency this will be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexcluded from the adjoint pass, and will not appear as a tensor in the adjoint norm.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Convert to flattened state.\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m shapes, func, y0, t, rtol, atol, method, options, event_fn, decreasing_time \u001b[38;5;241m=\u001b[39m \u001b[43m_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSOLVERS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# Handle the adjoint norm function.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m state_norm \u001b[38;5;241m=\u001b[39m options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mysoden/lib/python3.10/site-packages/torchdiffeq/_impl/misc.py:213\u001b[0m, in \u001b[0;36m_check_inputs\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn, SOLVERS)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m         event_fn \u001b[38;5;241m=\u001b[39m _TupleInputOnlyFunc(event_fn, shapes)\n\u001b[0;32m--> 213\u001b[0m \u001b[43m_assert_floating\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# Normalise method and options\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mysoden/lib/python3.10/site-packages/torchdiffeq/_impl/misc.py:106\u001b[0m, in \u001b[0;36m_assert_floating\u001b[0;34m(name, t)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_assert_floating\u001b[39m(name, t):\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_floating_point(t):\n\u001b[0;32m--> 106\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m` must be a floating point Tensor but is a \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, t\u001b[38;5;241m.\u001b[39mtype()))\n",
      "\u001b[0;31mTypeError\u001b[0m: `y0` must be a floating point Tensor but is a torch.LongTensor"
     ]
    }
   ],
   "source": [
    "model(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a39083-2430-4b65-a738-169b17e0fb18",
   "metadata": {},
   "source": [
    "## Test dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "49c60751-bd4e-4d36-af9f-24169a8b81dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import (BatchSampler, DataLoader, Dataset, RandomSampler,\n",
    "                              SequentialSampler)\n",
    "from torch.utils.data.dataloader import default_collate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded08491-9182-40f0-adaa-d04a89fcdef2",
   "metadata": {},
   "source": [
    "### get_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "99aa2192-220d-4541-952f-00a8a92f7cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 8 2 8 2 7 2 2 0 7]\n"
     ]
    }
   ],
   "source": [
    "t = np.random.randint(0, 10, size = 10)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b02b1b59-dda3-43e6-932b-6066616f2992",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "N = len(t)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c9b52bad-93bf-41b8-b54c-d902cc5eb3b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 2 4 6 7 0 5 9 1 3]\n"
     ]
    }
   ],
   "source": [
    "idx = np.argsort(t)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e113acfd-126d-4177-be30-e4c1ff6215e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 2 2 2 7 7 7 8 8]\n"
     ]
    }
   ],
   "source": [
    "t = t[idx]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5710d982-bd1a-40d0-842f-7f61772efcf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "delta = np.random.randint(0, 2, size = 10)\n",
    "print(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a535fe4f-0952-4c30-a718-4c2e61bc7293",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "delta = delta[idx]\n",
    "print(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4a6fd87b-949c-45e3-b9d1-2a8be9441d23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  7 11  8 13  8 12  8 11  8]\n",
      " [ 6  6  1  9  5  1  2  7 12  4]\n",
      " [ 3 11  1  1  7 10  8 10 13  5]\n",
      " [ 8  7  5  9 12 12 12  9  4  1]\n",
      " [ 7  9  8 12 11  6 12 13  6  9]\n",
      " [ 9  6 14 14 12  1  5 14  1  4]\n",
      " [12 11 13  2 12 11 14  1 10 13]\n",
      " [10 11  2 12  8  5 11 12 12  4]\n",
      " [13  7  4  3  9  3  4  7  4  7]\n",
      " [ 1  7  8  8  7  6  2 13  6  3]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randint(1, 15, size = (10, 10))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e5755e86-53cd-43fe-8c97-da5052e762bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "init_cond = np.zeros_like(t)\n",
    "print(init_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "66841546-caf3-4eae-84e5-e34531dbd79b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "labels = torch.tensor(delta, dtype=torch.float)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3343f761-7f29-4d47-9aa5-5e3d98e66734",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t': tensor([0., 2., 2., 2., 2., 7., 7., 7., 8., 8.]), 'init_cond': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'features': tensor([[12.,  7., 11.,  8., 13.,  8., 12.,  8., 11.,  8.],\n",
      "        [ 6.,  6.,  1.,  9.,  5.,  1.,  2.,  7., 12.,  4.],\n",
      "        [ 3., 11.,  1.,  1.,  7., 10.,  8., 10., 13.,  5.],\n",
      "        [ 8.,  7.,  5.,  9., 12., 12., 12.,  9.,  4.,  1.],\n",
      "        [ 7.,  9.,  8., 12., 11.,  6., 12., 13.,  6.,  9.],\n",
      "        [ 9.,  6., 14., 14., 12.,  1.,  5., 14.,  1.,  4.],\n",
      "        [12., 11., 13.,  2., 12., 11., 14.,  1., 10., 13.],\n",
      "        [10., 11.,  2., 12.,  8.,  5., 11., 12., 12.,  4.],\n",
      "        [13.,  7.,  4.,  3.,  9.,  3.,  4.,  7.,  4.,  7.],\n",
      "        [ 1.,  7.,  8.,  8.,  7.,  6.,  2., 13.,  6.,  3.]]), 'index': tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}\n"
     ]
    }
   ],
   "source": [
    "features = {}\n",
    "features[\"t\"] = torch.tensor(t, dtype=torch.float)\n",
    "features[\"init_cond\"] = torch.tensor(init_cond, dtype=torch.float)\n",
    "features[\"features\"] = torch.tensor(x, dtype=torch.float)\n",
    "features[\"index\"] = torch.arange(N, dtype=torch.long)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d13e780e-23b6-4662-9205-434c2bde427c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DictDataset.\n",
    "class DictDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_features = {}\n",
    "        for key in self.features:\n",
    "            sample_features[key] = self.features[key][idx]\n",
    "        return sample_features, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c895f75b-23ca-490c-9930-1fcd2b1e1439",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.DictDataset object at 0x7f8a7f7fc790>\n"
     ]
    }
   ],
   "source": [
    "dataset = DictDataset(features, labels)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f7c612a7-e788-43d8-836b-840b7ad18428",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Batch random sampler that maintains order within each batch.\n",
    "class OrderedBatchRandomSampler(object):\n",
    "    def __init__(self, n, batch_size, seed=13, drop_last=False):\n",
    "        super(OrderedBatchRandomSampler, self).__init__()\n",
    "        self.n = n\n",
    "        self.batch_size = batch_size\n",
    "        self.seed = seed\n",
    "        self.drop_last = drop_last\n",
    "        self.random_state = np.random.RandomState(seed)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.drop_last:\n",
    "            return self.n // self.batch_size\n",
    "        else:\n",
    "            return (self.n + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        batch = []\n",
    "        for idx in self.random_state.permutation(self.n):  ## generate random indices\n",
    "            batch.append(idx)\n",
    "            if len(batch) == self.batch_size:\n",
    "                yield sorted(batch)\n",
    "                batch = []\n",
    "        if len(batch) > 0 and not self.drop_last:\n",
    "            yield sorted(batch)  ## Return sends a specified value back to its caller whereas Yield can produce a sequence of values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d4eba6e6-6617-4688-8db3-4eb57eeeef89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampler = OrderedBatchRandomSampler(N, batch_size = 2, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "71d7d6b8-856a-4fa6-b05e-aada09607b8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_collate_fn = default_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e71e06da-e994-40b5-a071-1f90893acc69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f8a7f7fc7f0>\n"
     ]
    }
   ],
   "source": [
    "NUM_WORKERS = 0\n",
    "dataloader = DataLoader(\n",
    "        dataset, batch_sampler=sampler, collate_fn=_collate_fn, pin_memory=True,\n",
    "        num_workers=NUM_WORKERS)\n",
    "print(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "aca4973f-f33b-4d32-87d9-bdf1127c5616",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'t': tensor([2., 7.]), 'init_cond': tensor([0., 0.]), 'features': tensor([[ 8.,  7.,  5.,  9., 12., 12., 12.,  9.,  4.,  1.],\n",
      "        [ 9.,  6., 14., 14., 12.,  1.,  5., 14.,  1.,  4.]]), 'index': tensor([3, 5])}, tensor([1., 0.])]\n",
      "[{'t': tensor([2., 7.]), 'init_cond': tensor([0., 0.]), 'features': tensor([[ 6.,  6.,  1.,  9.,  5.,  1.,  2.,  7., 12.,  4.],\n",
      "        [12., 11., 13.,  2., 12., 11., 14.,  1., 10., 13.]]), 'index': tensor([1, 6])}, tensor([1., 0.])]\n",
      "[{'t': tensor([2., 7.]), 'init_cond': tensor([0., 0.]), 'features': tensor([[ 7.,  9.,  8., 12., 11.,  6., 12., 13.,  6.,  9.],\n",
      "        [10., 11.,  2., 12.,  8.,  5., 11., 12., 12.,  4.]]), 'index': tensor([4, 7])}, tensor([0., 0.])]\n",
      "[{'t': tensor([8., 8.]), 'init_cond': tensor([0., 0.]), 'features': tensor([[13.,  7.,  4.,  3.,  9.,  3.,  4.,  7.,  4.,  7.],\n",
      "        [ 1.,  7.,  8.,  8.,  7.,  6.,  2., 13.,  6.,  3.]]), 'index': tensor([8, 9])}, tensor([0., 0.])]\n",
      "[{'t': tensor([0., 2.]), 'init_cond': tensor([0., 0.]), 'features': tensor([[12.,  7., 11.,  8., 13.,  8., 12.,  8., 11.,  8.],\n",
      "        [ 3., 11.,  1.,  1.,  7., 10.,  8., 10., 13.,  5.]]), 'index': tensor([0, 2])}, tensor([0., 0.])]\n"
     ]
    }
   ],
   "source": [
    "for batch_data in dataloader:\n",
    "    print(batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d5c04f35-5d3b-41cf-a17b-5dbbdbd5f05d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr_0\n",
      "[[ 0.5778179  -0.59537214  0.13440911 ... -0.18676585 -1.3885338\n",
      "   2.489657  ]\n",
      " [ 1.1923819  -1.5297642   0.13440911 ... -0.18676585 -1.3885338\n",
      "   2.489657  ]\n",
      " [-0.6891113  -1.0625682   2.0835433  ... -0.18676585 -1.3885338\n",
      "   2.489657  ]\n",
      " ...\n",
      " [-0.9417017  -0.05629976 -0.8087203  ... -0.18676585  0.72018415\n",
      "  -0.40166175]\n",
      " [ 1.1944975   0.9499686   0.3859103  ... -0.18676585  0.72018415\n",
      "  -0.40166175]\n",
      " [ 0.83124214  0.8780922   0.3859103  ... -0.18676585 -1.3885338\n",
      "   2.489657  ]]\n",
      "(1727, 27)\n",
      "arr_1\n",
      "[[4.18891191 0.        ]\n",
      " [0.05201916 1.        ]\n",
      " [0.75017112 1.        ]\n",
      " ...\n",
      " [1.66461325 0.        ]\n",
      " [0.09856263 1.        ]\n",
      " [0.02737851 1.        ]]\n",
      "(1727, 2)\n",
      "arr_2\n",
      "[[ 71.45795  68.      102.      ...   0.        0.        1.     ]\n",
      " [ 81.03198  42.      102.      ...   0.        0.        1.     ]\n",
      " [ 51.72098  55.      164.      ...   0.        0.        1.     ]\n",
      " ...\n",
      " [ 47.78598  83.       72.      ...   0.        1.        0.     ]\n",
      " [ 81.06494 111.      110.      ...   0.        1.        0.     ]\n",
      " [ 75.40594 109.      110.      ...   0.        0.        1.     ]]\n",
      "(1727, 27)\n"
     ]
    }
   ],
   "source": [
    "from numpy import load\n",
    "\n",
    "data = load('data/support/test_1.npz')\n",
    "lst = data.files\n",
    "for item in lst:\n",
    "    print(item)\n",
    "    print(data[item])\n",
    "    print(data[item].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7985e3b2-6e57-4a85-afd1-f4cd745ac6cb",
   "metadata": {},
   "source": [
    "## Test survival_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0968b818-975c-4a94-95bb-2c13f8be4a80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = torch.linspace(1, 10, 20, dtype=torch.float32, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db7b8b17-c8c1-40cf-836a-accdfebd8dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  1.4737,  1.9474,  2.4211,  2.8947,  3.3684,  3.8421,  4.3158,\n",
       "         4.7895,  5.2632,  5.7368,  6.2105,  6.6842,  7.1579,  7.6316,  8.1053,\n",
       "         8.5789,  9.0526,  9.5263, 10.0000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb25280-3d44-45f1-82c8-84dc4cd3467a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
